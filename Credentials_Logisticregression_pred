
#adding the credential to the Apache CouchDB / Cloudant database where your sensor data ist stored
credentials_1 = {
  'password':"""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx""",
  'custom_url':'https://ab28a05d-e0f8-43a2-9930-cfa9e2737b8f-bluemix:4b5403df0d792637f53845b5b93c089d8fc7f225ba85306f0deeaa4518df1804@ab28a05d-e0f8-43a2-9930-cfa9e2737b8f-bluemix.cloudant.com',
  'username':'ab28a05d-e0f8-43a2-9930-cfa9e2737b8f-bluemix'
}

#opening the spark session
spark = SparkSession\
    .builder\
    .appName("Cloudant Spark SQL Example in Python using temp tables")\
    .config("cloudant.host",credentials_1['custom_url'].split('@')[1])\
    .config("cloudant.username", credentials_1['username'])\
    .config("cloudant.password",credentials_1['password'])\
    .getOrCreate()
    
 
 #reading the data
df=spark.read.load('shake', "org.apache.bahir.cloudant")
df.createOrReplaceTempView("df")
spark.sql("SELECT * from df").show()

#create a VectorAssembler which consumed columns X, Y and Z and produces a column “features”
from pyspark.ml.feature import VectorAssembler
vectorAssembler = VectorAssembler(inputCols = ['X','Y','Z'], outputCol = "features")

#insatiate a classifier from the SparkML package and assign it to the classifier variable
from pyspark.sql.functions import when
#df = df.withColumn('label', when (df['CLASS']==0,1).otherwise(0))
df = df.withColumn('label', df['CLASS'])
df.show()

#apply Logisticregression
from pyspark.ml.classification import LogisticRegression
classifier = LogisticRegression(labelCol="label", featuresCol="features", maxIter=10)

#train and apply
from pyspark.ml import Pipeline
pipeline = Pipeline(stages=[vectorAssembler, classifier])
model = pipeline.fit(df)
prediction = model.transform(df)
prediction.show(3)

#Evaluate
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
binEval = MulticlassClassificationEvaluator().setMetricName("accuracy") .setPredictionCol("prediction").setLabelCol("label")
    
binEval.evaluate(prediction)
